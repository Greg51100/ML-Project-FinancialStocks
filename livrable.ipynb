{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d406fd89",
   "metadata": {},
   "source": [
    "# US Stock Market Prediction (2014-2018)\n",
    "**Authors:** David PAGNIEZ, Antoine KRYCHOWSKI, Gregoire MEHAH\n",
    "\n",
    "## 1. Project Objective\n",
    "The goal of this project is to analyze financial indicators of US companies from 2014 to 2018 and build a machine learning model to predict stock performance.\n",
    "\n",
    "Our approach follows these steps:\n",
    "1.  **Data Cleaning:** Handling missing values and outliers in financial data.\n",
    "2.  **Baseline Model:** Attempting to predict the exact price variation (Regression).\n",
    "3.  **Classification:** Switching to a trend prediction (Buy/Sell) if regression fails.\n",
    "4.  **Optimization:** Using Feature Engineering and Ensemble methods to improve results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82f77608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded 2014_Financial_Data.csv\n",
      "Loaded 2015_Financial_Data.csv\n",
      "Loaded 2016_Financial_Data.csv\n",
      "Loaded 2017_Financial_Data.csv\n",
      "Loaded 2018_Financial_Data.csv\n",
      "Initial Dataset Shape: (22077, 225)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoi\\AppData\\Local\\Temp\\ipykernel_24232\\3272686016.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['Target_Price_Var'] = data[target_cols].bfill(axis=1).iloc[:, 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "\n",
    "# Visual configuration\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "# 1. Loading Data\n",
    "# We iterate through the CSV files to merge them into a single dataframe.\n",
    "years = [2014, 2015, 2016, 2017, 2018]\n",
    "dfs = []\n",
    "\n",
    "print(\"Loading data...\")\n",
    "for year in years:\n",
    "    try:\n",
    "        filename = f'{year}_Financial_Data.csv'\n",
    "        df = pd.read_csv(filename)\n",
    "        df['Year'] = year\n",
    "        dfs.append(df)\n",
    "        print(f\"Loaded {filename}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {filename} not found.\")\n",
    "\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# 2. Target Consolidation\n",
    "# The target column name is not consistent across files, so we merge them.\n",
    "target_cols = [col for col in data.columns if 'PRICE VAR' in col]\n",
    "data['Target_Price_Var'] = data[target_cols].bfill(axis=1).iloc[:, 0]\n",
    "data['Target_Price_Var'] = pd.to_numeric(data['Target_Price_Var'], errors='coerce')\n",
    "\n",
    "# Dropping useless columns\n",
    "cols_to_drop = target_cols + ['Class', 'Unnamed: 0', 'Symbol']\n",
    "data = data.drop(columns=[c for c in cols_to_drop if c in data.columns])\n",
    "\n",
    "print(f\"Initial Dataset Shape: {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9ee178",
   "metadata": {},
   "source": [
    "## 2. Preprocessing and Outlier Management\n",
    "\n",
    "Financial data is known to be very noisy. Some companies are massive (Apple, Google), while others are small. Additionally, some data points seem to be errors (e.g., a 10,000% increase).\n",
    "\n",
    "If we leave these outliers, they will bias the model.\n",
    "Strategy: We apply Winsorization (Clipping). We cap the values at the 1st and 99th percentiles to remove extreme outliers without deleting too much data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef9d2fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing done. Outliers have been clipped.\n"
     ]
    }
   ],
   "source": [
    "# 1. Remove rows where the target is missing\n",
    "data_clean = data.dropna(subset=['Target_Price_Var']).copy()\n",
    "\n",
    "# 2. Remove columns with too many missing values (> 40%)\n",
    "threshold = 0.4\n",
    "data_clean = data_clean.dropna(thresh=len(data_clean) * (1 - threshold), axis=1)\n",
    "\n",
    "# 3. Winsorization (Clipping)\n",
    "# We limit the Target between -99% (almost bankruptcy) and +500% (x5)\n",
    "data_clean['Target_Price_Var'] = data_clean['Target_Price_Var'].clip(lower=-99, upper=500)\n",
    "\n",
    "# We limit the Features between the 1st and 99th quantile\n",
    "numeric_cols = data_clean.select_dtypes(include=np.number).columns.drop(['Year', 'Target_Price_Var'])\n",
    "lower_bounds = data_clean[numeric_cols].quantile(0.01)\n",
    "upper_bounds = data_clean[numeric_cols].quantile(0.99)\n",
    "\n",
    "data_clean[numeric_cols] = data_clean[numeric_cols].clip(lower=lower_bounds, upper=upper_bounds, axis=1)\n",
    "\n",
    "print(\"Preprocessing done. Outliers have been clipped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61fc3ff",
   "metadata": {},
   "source": [
    "## 3. First Approach: Linear Regression\n",
    "\n",
    "Our first hypothesis was to predict the exact percentage of price variation.\n",
    "We used a standard Linear Regression model.\n",
    "\n",
    "*   Train set: 2014, 2015, 2016\n",
    "*   Test set: 2018 (to simulate real future prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b377fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Results:\n",
      "R2 Score: -0.1006\n",
      "Mean Absolute Error (MAE): 38.91%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Temporal Split\n",
    "train = data_clean[data_clean['Year'].isin([2014, 2015, 2016])]\n",
    "test = data_clean[data_clean['Year'] == 2018]\n",
    "\n",
    "# --- CORRECTION ICI : On ne garde que les chiffres ---\n",
    "# .select_dtypes(include=np.number) vire automatiquement les colonnes de texte (Secteur, etc.)\n",
    "X_train = train.drop(columns=['Target_Price_Var', 'Year']).select_dtypes(include=np.number)\n",
    "y_train = train['Target_Price_Var']\n",
    "\n",
    "X_test = test.drop(columns=['Target_Price_Var', 'Year']).select_dtypes(include=np.number)\n",
    "y_test = test['Target_Price_Var']\n",
    "\n",
    "# Pipeline: Imputation -> Scaling -> Regression\n",
    "reg_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')), # Maintenant ça marche car tout est numérique\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "reg_pipeline.fit(X_train, y_train)\n",
    "preds_reg = reg_pipeline.predict(X_test)\n",
    "\n",
    "print(\"Linear Regression Results:\")\n",
    "print(f\"R2 Score: {r2_score(y_test, preds_reg):.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mean_absolute_error(y_test, preds_reg):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f233f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27502699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
